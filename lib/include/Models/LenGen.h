#pragma once

#include <CUNET.h>

namespace cunet
{
    class LenGen
    {
        public:
        LenGen()
        {
           float weight0[] = {0.0002550101198721677, -3.2178804874420166, 0.00018269904830958694, -1.7809468507766724, -1.0937395095825195, -0.22625696659088135, 4.636596713680774e-05, 0.48299458622932434, -0.6090973019599915, -1.8714637756347656, 3.483163163764402e-05, -0.6770139336585999, -0.6929045915603638, -1.3347586393356323, -7.80533991928678e-06, -0.3381926119327545, 0.0006111178663559258, 1.5798898935317993, 8.989849220597534e-07, 0.8187687397003174, -1.3049988746643066, 0.95521479845047, -0.00017153378576040268, 1.2790558338165283, 0.004009723663330078, -1.3578535318374634, 0.00020310193940531462, -0.8401366472244263, -0.00011466524301795289, -0.6300269365310669, -0.0001735131663735956, -0.30266907811164856, };
           float bias0[] = {-1.1049110889434814, 0.01920956000685692, -0.789876401424408, -0.37336593866348267, 1.2935806512832642, 0.3817387521266937, -0.6451255679130554, -0.7275131940841675, };
           linear2 = Linear<float>(4, 8, weight0, bias0);
           softplus3 = Softplus<float>();
           float weight2[] = {0.32078322768211365, 2.2930846214294434, -0.4302404522895813, 0.8623097538948059, 0.07639728486537933, -7.344297885894775, 0.1517505645751953, 0.08111777901649475, 0.8980022072792053, 0.24542896449565887, -0.39900559186935425, -0.2379428595304489, -0.4218999743461609, 0.550153374671936, 0.19281478226184845, 0.2665518522262573, 1.1192340850830078, -0.5735034942626953, 0.45667654275894165, 0.5679449439048767, 0.17392270267009735, -0.7650308609008789, -0.394309937953949, -0.2378038465976715, -1.3438702821731567, 0.36192813515663147, 1.2459357976913452, 0.1934725046157837, -0.16042760014533997, 0.18294019997119904, -0.16101548075675964, -0.7128762602806091, -0.3771834373474121, 0.24984949827194214, 0.21548236906528473, -0.4003368616104126, -0.6789369583129883, 0.36920875310897827, 0.5720261931419373, 0.08241995424032211, -3.2644495964050293, -1.9642665386199951, 2.4269137382507324, 2.816319704055786, -0.2557685375213623, 1.118498682975769, 0.11422757059335709, -1.1520274877548218, 0.2826833128929138, 0.028265632688999176, 0.21437667310237885, 0.1391800493001938, -0.19960817694664001, 0.5783576369285583, 0.12339255213737488, 0.30832189321517944, 0.5503551959991455, 6.104694366455078, 2.4247078895568848, -0.3532871603965759, 0.37086254358291626, -17.936342239379883, 0.21232905983924866, 0.11042410880327225, };
           float bias2[] = {0.41951102018356323, -0.2906704843044281, -0.11608117818832397, -0.07559166103601456, -0.0033559948205947876, 2.5952494144439697, -0.2298421561717987, 0.5129215717315674, };
           linear4 = Linear<float>(8, 8, weight2, bias2);
           softplus5 = Softplus<float>();
           float weight4[] = {0.5978928208351135, 2.7223312854766846, -0.1923004537820816, -1.252432107925415, -0.8682274222373962, -2.198011875152588, -0.7686893939971924, 0.15988251566886902, 0.48678621649742126, -0.3105340600013733, -0.38163793087005615, 0.2244119942188263, 0.3660117983818054, -1.0896227359771729, 0.2336503565311432, -0.2885066866874695, 0.2587907314300537, -0.07433629781007767, 0.09557503461837769, -0.5166143178939819, 0.24805878102779388, -0.12246295064687729, 0.2850370407104492, -0.3091685473918915, 0.9396389126777649, 0.5811898708343506, 0.10853700339794159, -0.018008820712566376, -0.30811548233032227, 0.5569004416465759, -0.2671235501766205, -26.6728458404541, 0.0962262898683548, 0.9038938879966736, 0.15827004611492157, 0.012760277837514877, 0.4242991805076599, -0.7549431324005127, -0.4150300621986389, 0.7231894135475159, 0.550363302230835, 1.0042072534561157, -0.15640802681446075, 0.24850265681743622, -0.2192438244819641, 1.8780622482299805, -0.3537500202655792, 0.5730315446853638, 0.08625989407300949, 0.11350178718566895, 0.2868538498878479, 0.656502902507782, 0.15739163756370544, -1.2061965465545654, -0.1740504950284958, 0.6626114845275879, -0.4388635754585266, 0.02860165759921074, -0.09443752467632294, -0.45469820499420166, 0.22528479993343353, 2.3265655040740967, 0.373646080493927, 0.4766779839992523, };
           float bias4[] = {-0.8810510635375977, -0.11715693771839142, -0.003760924795642495, -0.025480259209871292, -0.8463295102119446, -0.28447335958480835, 0.3500487208366394, 0.05111464112997055, };
           linear6 = Linear<float>(8, 8, weight4, bias4);
           softplus7 = Softplus<float>();
           float weight6[] = {0.43587762117385864, 0.6409459710121155, 0.5151621699333191, -0.42258602380752563, -0.6089451313018799, 0.08441751450300217, 0.467594712972641, 0.028445838019251823, -0.7591418623924255, -1.596671223640442, -2.8225364685058594, 1.9525492191314697, 1.792291283607483, -1.221254587173462, 1.1118803024291992, -2.068190336227417, };
           float bias6[] = {-0.1919078379869461, -1.5821512937545776, };
           linear8 = Linear<float>(8, 2, weight6, bias6);
        }

        __device__
        Tensor<float>& operator()(Tensor<float>& x)
        {
            x = linear2(x);
            x = softplus3(x);
            x = linear4(x);
            x = softplus5(x);
            x = linear6(x);
            x = softplus7(x);
            x = linear8(x);
            return x;
        }

        private:
        Linear<float> linear2;
        Softplus<float> softplus3;
        Linear<float> linear4;
        Softplus<float> softplus5;
        Linear<float> linear6;
        Softplus<float> softplus7;
        Linear<float> linear8;
    }; // class
} // namespace cunet